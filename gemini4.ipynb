{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a6f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ARF\\my-repos\\RBL-AnalisisData-ML\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,155</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m18,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)             │         \u001b[38;5;34m1,155\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,411</span> (83.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,411\u001b[0m (83.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,411</span> (83.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,411\u001b[0m (83.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the LSTM model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1389 - loss: 2.7986 - val_accuracy: 0.3092 - val_loss: 1.7489\n",
      "Epoch 2/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2909 - loss: 1.8102 - val_accuracy: 0.3870 - val_loss: 1.4656\n",
      "Epoch 3/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3417 - loss: 1.5786 - val_accuracy: 0.4562 - val_loss: 1.3127\n",
      "Epoch 4/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3668 - loss: 1.4752 - val_accuracy: 0.4461 - val_loss: 1.2465\n",
      "Epoch 5/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3810 - loss: 1.4107 - val_accuracy: 0.4879 - val_loss: 1.1900\n",
      "Epoch 6/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3901 - loss: 1.3811 - val_accuracy: 0.4861 - val_loss: 1.1582\n",
      "Epoch 7/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4097 - loss: 1.3268 - val_accuracy: 0.5008 - val_loss: 1.1199\n",
      "Epoch 8/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4101 - loss: 1.3090 - val_accuracy: 0.4953 - val_loss: 1.0971\n",
      "Epoch 9/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4224 - loss: 1.2717 - val_accuracy: 0.4982 - val_loss: 1.0743\n",
      "Epoch 10/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4250 - loss: 1.2616 - val_accuracy: 0.5006 - val_loss: 1.0647\n",
      "Epoch 11/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4332 - loss: 1.2356 - val_accuracy: 0.5252 - val_loss: 1.0496\n",
      "Epoch 12/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4323 - loss: 1.2266 - val_accuracy: 0.5209 - val_loss: 1.0222\n",
      "Epoch 13/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4398 - loss: 1.2079 - val_accuracy: 0.5121 - val_loss: 1.0120\n",
      "Epoch 14/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4496 - loss: 1.1889 - val_accuracy: 0.5151 - val_loss: 0.9952\n",
      "Epoch 15/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4512 - loss: 1.1751 - val_accuracy: 0.5170 - val_loss: 0.9907\n",
      "Epoch 16/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4590 - loss: 1.1576 - val_accuracy: 0.5348 - val_loss: 0.9675\n",
      "Epoch 17/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4587 - loss: 1.1573 - val_accuracy: 0.5309 - val_loss: 0.9576\n",
      "Epoch 18/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4688 - loss: 1.1330 - val_accuracy: 0.5289 - val_loss: 0.9581\n",
      "Epoch 19/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4690 - loss: 1.1243 - val_accuracy: 0.5520 - val_loss: 0.9387\n",
      "Epoch 20/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4664 - loss: 1.1213 - val_accuracy: 0.5348 - val_loss: 0.9383\n",
      "Epoch 21/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4764 - loss: 1.1131 - val_accuracy: 0.5461 - val_loss: 0.9267\n",
      "Epoch 22/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4754 - loss: 1.1037 - val_accuracy: 0.5342 - val_loss: 0.9242\n",
      "Epoch 23/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4792 - loss: 1.0970 - val_accuracy: 0.5242 - val_loss: 0.9272\n",
      "Epoch 24/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4798 - loss: 1.0914 - val_accuracy: 0.5481 - val_loss: 0.9150\n",
      "Epoch 25/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4851 - loss: 1.0818 - val_accuracy: 0.5596 - val_loss: 0.9118\n",
      "Epoch 26/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4853 - loss: 1.0776 - val_accuracy: 0.5369 - val_loss: 0.9143\n",
      "Epoch 27/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4877 - loss: 1.0724 - val_accuracy: 0.5573 - val_loss: 0.8957\n",
      "Epoch 28/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4967 - loss: 1.0630 - val_accuracy: 0.5618 - val_loss: 0.8684\n",
      "Epoch 29/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5052 - loss: 1.0494 - val_accuracy: 0.5739 - val_loss: 0.8607\n",
      "Epoch 30/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5074 - loss: 1.0347 - val_accuracy: 0.5727 - val_loss: 0.8574\n",
      "Epoch 31/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5043 - loss: 1.0335 - val_accuracy: 0.5739 - val_loss: 0.8520\n",
      "Epoch 32/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5031 - loss: 1.0313 - val_accuracy: 0.5713 - val_loss: 0.8478\n",
      "Epoch 33/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5079 - loss: 1.0237 - val_accuracy: 0.5841 - val_loss: 0.8307\n",
      "Epoch 34/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5075 - loss: 1.0241 - val_accuracy: 0.5653 - val_loss: 0.8323\n",
      "Epoch 35/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: 1.0176 - val_accuracy: 0.5903 - val_loss: 0.8396\n",
      "Epoch 36/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5100 - loss: 1.0153 - val_accuracy: 0.5794 - val_loss: 0.8189\n",
      "Epoch 37/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5113 - loss: 1.0057 - val_accuracy: 0.5786 - val_loss: 0.8263\n",
      "Epoch 38/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5135 - loss: 0.9992 - val_accuracy: 0.5841 - val_loss: 0.8195\n",
      "Epoch 39/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5109 - loss: 1.0020 - val_accuracy: 0.5708 - val_loss: 0.8269\n",
      "Epoch 40/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5177 - loss: 1.0023 - val_accuracy: 0.5866 - val_loss: 0.8194\n",
      "Epoch 41/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5151 - loss: 1.0011 - val_accuracy: 0.5762 - val_loss: 0.8144\n",
      "Epoch 42/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5184 - loss: 0.9934 - val_accuracy: 0.5940 - val_loss: 0.8143\n",
      "Epoch 43/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5170 - loss: 0.9971 - val_accuracy: 0.5768 - val_loss: 0.8136\n",
      "Epoch 44/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5140 - loss: 0.9923 - val_accuracy: 0.5831 - val_loss: 0.8110\n",
      "Epoch 45/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 0.9867 - val_accuracy: 0.5780 - val_loss: 0.8141\n",
      "Epoch 46/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.9866 - val_accuracy: 0.5796 - val_loss: 0.8139\n",
      "Epoch 47/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5152 - loss: 0.9843 - val_accuracy: 0.5852 - val_loss: 0.8032\n",
      "Epoch 48/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5209 - loss: 0.9851 - val_accuracy: 0.5776 - val_loss: 0.8032\n",
      "Epoch 49/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5173 - loss: 0.9847 - val_accuracy: 0.5782 - val_loss: 0.8158\n",
      "Epoch 50/50\n",
      "\u001b[1m1439/1439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5232 - loss: 0.9750 - val_accuracy: 0.5655 - val_loss: 0.8028\n",
      "Model training complete.\n",
      "\n",
      "Evaluating the model on the test set...\n",
      "Test Loss: 0.8073\n",
      "Test Accuracy: 0.5724\n",
      "\n",
      "Making predictions on the test set...\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "1 MERCURY BARYCENTER       0.00      0.00      0.00       365\n",
      "              10 SUN       1.00      1.00      1.00       365\n",
      "         199 MERCURY       0.50      1.00      0.67       365\n",
      "  2 VENUS BARYCENTER       0.46      0.18      0.26       366\n",
      "           299 VENUS       0.49      0.78      0.60       365\n",
      "  3 EARTH BARYCENTER       0.47      0.95      0.62       365\n",
      "            301 MOON       1.00      0.88      0.93       366\n",
      "           399 EARTH       0.24      0.02      0.04       366\n",
      "   4 MARS BARYCENTER       1.00      1.00      1.00       365\n",
      "5 JUPITER BARYCENTER       1.00      1.00      1.00       365\n",
      " 6 SATURN BARYCENTER       0.00      0.00      0.00       366\n",
      "           601 MIMAS       0.50      0.99      0.66       365\n",
      "       602 ENCELADUS       1.00      1.00      1.00       365\n",
      "          603 TETHYS       0.32      0.24      0.27       365\n",
      "           604 DIONE       0.00      0.00      0.00       366\n",
      "            605 RHEA       1.00      1.00      1.00       365\n",
      "           606 TITAN       0.51      1.00      0.67       365\n",
      "        607 HYPERION       1.00      0.00      0.01       365\n",
      "         608 IAPETUS       0.97      0.99      0.98       366\n",
      "          609 PHOEBE       0.99      1.00      1.00       365\n",
      "          612 HELENE       0.33      0.28      0.30       366\n",
      "         613 TELESTO       0.33      0.00      0.01       365\n",
      "         614 CALYPSO       0.33      0.74      0.46       366\n",
      "         632 METHONE       0.00      0.00      0.00       366\n",
      "      634 POLYDEUCES       0.34      0.74      0.47       365\n",
      "          699 SATURN       0.50      1.00      0.67       366\n",
      " 7 URANUS BARYCENTER       1.00      1.00      1.00       365\n",
      "8 NEPTUNE BARYCENTER       1.00      1.00      1.00       365\n",
      "  9 PLUTO BARYCENTER       0.39      1.00      0.56       366\n",
      "          901 CHARON       0.78      0.37      0.50       365\n",
      "             902 NIX       0.22      0.78      0.35       366\n",
      "           903 HYDRA       0.27      0.05      0.08       366\n",
      "        904 KERBEROS       0.00      0.00      0.00       365\n",
      "            905 STYX       0.00      0.00      0.00       365\n",
      "           999 PLUTO       0.19      0.05      0.08       366\n",
      "\n",
      "            accuracy                           0.57     12789\n",
      "           macro avg       0.52      0.57      0.49     12789\n",
      "        weighted avg       0.52      0.57      0.49     12789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def predict_celestial_body_name_lstm(csv_file_path):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model to predict the 'name' of celestial bodies from their\n",
    "    positional and velocity data.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file containing the data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "        print(\"Please ensure the CSV file is in the same directory as the script or provide the full path.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    feature_columns = ['x_au', 'y_au', 'z_au', 'vx_au_per_day', 'vy_au_per_day', 'vz_au_per_day']\n",
    "    target_column = 'name'\n",
    "\n",
    "    # Check if all required columns are present\n",
    "    required_columns = feature_columns + [target_column]\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: The following required columns are missing from the CSV: {', '.join(missing_cols)}\")\n",
    "        return\n",
    "\n",
    "    # Drop rows with missing values in features or target\n",
    "    df.dropna(subset=required_columns, inplace=True)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Error: No data remaining after dropping rows with missing values. Cannot proceed.\")\n",
    "        return\n",
    "        \n",
    "    X = df[feature_columns]\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Encode the target variable 'name' as it's categorical\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_integer_encoded = label_encoder.fit_transform(y)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    # One-hot encode the integer encoded target variable for Keras\n",
    "    y_one_hot_encoded = to_categorical(y_integer_encoded, num_classes=num_classes)\n",
    "\n",
    "    # Scale the features (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Reshape X for LSTM: (samples, timesteps, features)\n",
    "    # Here, we treat each observation as a sequence of 1 timestep.\n",
    "    X_scaled_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    # Stratify by y_integer_encoded to ensure balanced classes in splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled_reshaped, y_one_hot_encoded, test_size=0.2, random_state=42, stratify=y_integer_encoded\n",
    "    )\n",
    "    \n",
    "    # Also keep a copy of y_test in integer encoded format for classification_report\n",
    "    _, _, y_train_int, y_test_int = train_test_split(\n",
    "        X_scaled_reshaped, y_integer_encoded, test_size=0.2, random_state=42, stratify=y_integer_encoded\n",
    "    )\n",
    "\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(\"Error: Not enough data to split into training and testing sets after preprocessing.\")\n",
    "        print(f\"Original data size: {len(df)}, Training data size: {len(X_train)}, Test data size: {len(X_test)}\")\n",
    "        return\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)) # units can be tuned\n",
    "    # model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)) # If adding more LSTM layers\n",
    "    # model.add(LSTM(units=32))\n",
    "    model.add(Dropout(0.3)) # Dropout for regularization\n",
    "    model.add(Dense(units=32, activation='relu')) # Hidden dense layer\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax')) # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    # Optimizer, loss function, and metrics can be tuned\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(\"\\nLSTM Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    print(\"\\nTraining the LSTM model...\")\n",
    "    try:\n",
    "        # Train the model\n",
    "        # Epochs and batch_size can be tuned\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        return\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    print(\"\\nEvaluating the model on the test set...\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    print(\"\\nMaking predictions on the test set...\")\n",
    "    y_pred_probabilities = model.predict(X_test)\n",
    "    y_pred_encoded = np.argmax(y_pred_probabilities, axis=1) # Convert probabilities to class labels\n",
    "\n",
    "    # Generate classification report\n",
    "    # y_test_int contains the original integer labels for the test set\n",
    "    report = classification_report(y_test_int, y_pred_encoded, target_names=label_encoder.classes_, zero_division=0)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Example of how to predict on new, unseen data:\n",
    "    # Create a dummy new data point (ensure it has the same features as training data)\n",
    "    # new_data_point_df = pd.DataFrame([{\n",
    "    #     'x_au': 0.0, 'y_au': 1.0, 'z_au': 0.0,\n",
    "    #     'vx_au_per_day': -0.01, 'vy_au_per_day': 0.0, 'vz_au_per_day': 0.0\n",
    "    # }])\n",
    "    # # Scale the new data using the SAME scaler fitted on the training data\n",
    "    # new_data_scaled = scaler.transform(new_data_point_df[feature_columns])\n",
    "    # # Reshape for LSTM\n",
    "    # new_data_reshaped = new_data_scaled.reshape((new_data_scaled.shape[0], 1, new_data_scaled.shape[1]))\n",
    "    # # Predict\n",
    "    # prediction_probabilities = model.predict(new_data_reshaped)\n",
    "    # predicted_class_encoded = np.argmax(prediction_probabilities, axis=1)\n",
    "    # # Convert encoded prediction back to original name\n",
    "    # predicted_name = label_encoder.inverse_transform(predicted_class_encoded)\n",
    "    # print(f\"\\nExample prediction for new data: {predicted_name[0]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT: Replace this with the actual path to your CSV file\n",
    "    # if it's not in the same directory as the script.\n",
    "    csv_file = './dataset/solar_system_positions_with_velocity.csv' \n",
    "    # Ensure you have TensorFlow installed: pip install tensorflow\n",
    "    predict_celestial_body_name_lstm(csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
